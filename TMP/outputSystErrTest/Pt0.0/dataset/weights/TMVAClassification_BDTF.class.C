// Class: ReadBDTF
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::BDTF
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.24/06       [399366]
Creator        : mjongerh
Date           : Wed Feb 23 14:57:17 2022
Host           : Linux alicecerno2 5.4.0-90-generic #101-Ubuntu SMP Fri Oct 15 20:00:55 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /home/mjongerh/alice/SharedFol/CERN/Lb
Training events: 3281
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
NTrees: "50" [Number of trees in the forest]
MaxDepth: "3" [Max depth of the decision tree allowed]
MinNodeSize: "2.5%" [Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%)]
nCuts: "20" [Number of grid points in variable range used in finding optimal cut in node splitting]
BoostType: "AdaBoost" [Boosting type for the trees in the forest (note: AdaCost is still experimental)]
AdaBoostBeta: "5.000000e-01" [Learning rate  for AdaBoost algorithm]
SeparationType: "giniindex" [Separation criterion for node splitting]
UseFisherCuts: "True" [Use multivariate splits using the Fisher criterion]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2]
UseBaggedBoost: "False" [Use only a random subsample of all events for growing the trees in each boost iteration.]
Shrinkage: "1.000000e+00" [Learning rate for BoostType=Grad algorithm]
UseRandomisedTrees: "False" [Determine at each node splitting the cut variable only as the best out of a random subset of variables (like in RandomForests)]
UseNvars: "3" [Size of the subset of variables used with RandomisedTree option]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Poisson distribution in each split with RandomisedTree option]
BaggedSampleFraction: "6.000000e-01" [Relative size of bagged event sample to original size of the data sample (used whenever bagging is used (i.e. UseBaggedBoost, Bagging,)]
UseYesNoLeaf: "True" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node -> Real-AdaBoost]
NegWeightTreatment: "inverseboostnegweights" [How to treat events with negative weights in the BDT training (particular the boosting) : IgnoreInTraining;  Boost With inverse boostweight; Pair events with negative and positive weights in training sample and *annihilate* them (experimental!)]
Css: "1.000000e+00" [AdaCost: cost of true signal selected signal]
Cts_sb: "1.000000e+00" [AdaCost: cost of true signal selected bkg]
Ctb_ss: "1.000000e+00" [AdaCost: cost of true bkg    selected signal]
Cbb: "1.000000e+00" [AdaCost: cost of true bkg    selected bkg ]
NodePurityLimit: "5.000000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
RegressionLossFunctionBDTG: "huber" [Loss function for BDTG regression.]
HuberQuantile: "7.000000e-01" [In the Huber loss function this is the quantile that separates the core from the tails in the residuals distribution.]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
DoPreselection: "False" [and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training]
SigToBkgFraction: "1.000000e+00" [Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost]
PruneMethod: "nopruning" [Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning:  Pruning: Method used for pruning (removal) of statistically insignificant branches ]
PruneStrength: "0.000000e+00" [Pruning strength]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
SkipNormalization: "False" [Skip normalization at initialization, to keep expectation value of BDT output according to the fraction of events]
nEventsMin: "0" [deprecated: Use MinNodeSize (in % of training events) instead]
UseBaggedGrad: "False" [deprecated: Use *UseBaggedBoost* instead:  Use only a random subsample of all events for growing the trees in each iteration.]
GradBaggingFraction: "6.000000e-01" [deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. ]
UseNTrainEvents: "0" [deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events used in randomised (and bagged) trees]
NNodesMax: "0" [deprecated: Use MaxDepth instead to limit the tree size]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 7
fCPA                          fCPA                          fCPA                          fCPA                          units                             'F'    [0.950047492981,0.999999940395]
fCPAXY                        fCPAXY                        fCPAXY                        fCPAXY                        units                             'F'    [-0.999990522861,1]
fChi2PCA                      fChi2PCA                      fChi2PCA                      fChi2PCA                      units                             'F'    [3.61386875286e-12,9.97164970613e-05]
fDecayLength                  fDecayLength                  fDecayLength                  fDecayLength                  units                             'F'    [0.00623603491113,113.972885132]
fDecayLengthXY                fDecayLengthXY                fDecayLengthXY                fDecayLengthXY                units                             'F'    [0.0050040059723,41.9688072205]
fImpactParameter0             fImpactParameter0             fImpactParameter0             fImpactParameter0             units                             'F'    [-0.0620930790901,0.0907993912697]
fImpactParameter1             fImpactParameter1             fImpactParameter1             fImpactParameter1             units                             'F'    [-2.24202203751,0.236704155803]
NSpec 4
fPtProng0                     fPtProng0                     fPtProng0                     fPtProng0                     units                             'F'    [0.500022649765,2.94130015373]
fPtProng1                     fPtProng1                     fPtProng1                     fPtProng1                     units                             'F'    [0.500992953777,2.78135895729]
fM                            fM                            fM                            fM                            units                             'F'    [4.6205201149,6.61918544769]
fPt                           fPt                           fPt                           fPt                           Gev                               'F'    [0.00697750691324,0.499976634979]


============================================================================ */

#include <array>
#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#include <algorithm>
#include <limits>

#define NN new BDTFNode

#ifndef BDTFNode__def
#define BDTFNode__def

class BDTFNode {

public:

   // constructor of an essentially "empty" node floating in space
   BDTFNode ( BDTFNode* left,BDTFNode* right,
                          int nFisherCoeff,
                          double fisherCoeff0,
                          double fisherCoeff1,
                          double fisherCoeff2,
                          double fisherCoeff3,
                          double fisherCoeff4,
                          double fisherCoeff5,
                          double fisherCoeff6,
                          double fisherCoeff7,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fNFisherCoeff ( nFisherCoeff ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
     fFisherCoeff.push_back(fisherCoeff0);
     fFisherCoeff.push_back(fisherCoeff1);
     fFisherCoeff.push_back(fisherCoeff2);
     fFisherCoeff.push_back(fisherCoeff3);
     fFisherCoeff.push_back(fisherCoeff4);
     fFisherCoeff.push_back(fisherCoeff5);
     fFisherCoeff.push_back(fisherCoeff6);
     fFisherCoeff.push_back(fisherCoeff7);
   }

   virtual ~BDTFNode();

   // test event if it descends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   BDTFNode* GetRight( void )  {return fRight; };

   // test event if it descends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   BDTFNode* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   BDTFNode*   fLeft;     // pointer to the left daughter node
   BDTFNode*   fRight;    // pointer to the right daughter node
   int                     fNFisherCoeff; // =0 if this node doesn't use fisher, else =nvar+1 
   std::vector<double>     fFisherCoeff;  // the fisher coeff (offset at the last element)
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value applied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 

//_______________________________________________________________________
   BDTFNode::~BDTFNode()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 

//_______________________________________________________________________
bool BDTFNode::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the right
   bool result;
   if (fNFisherCoeff == 0){
     result = (inputValues[fSelector] >= fCutValue );
   }else{
     double fisher = fFisherCoeff.at(fFisherCoeff.size()-1);
     for (unsigned int ivar=0; ivar<fFisherCoeff.size()-1; ivar++)
       fisher += fFisherCoeff.at(ivar)*inputValues.at(ivar);
     result = fisher > fCutValue;
   }
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}

//_______________________________________________________________________
bool BDTFNode::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}

#endif

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadBDTF : public IClassifierReader {

 public:

   // constructor
   ReadBDTF( std::vector<std::string>& theInputVars )
      : IClassifierReader(),
        fClassName( "ReadBDTF" ),
        fNvars( 7 )
   {
      // the training input variables
      const char* inputVars[] = { "fCPA", "fCPAXY", "fChi2PCA", "fDecayLength", "fDecayLengthXY", "fImpactParameter0", "fImpactParameter1" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;
      fVmin[4] = 0;
      fVmax[4] = 0;
      fVmin[5] = 0;
      fVmax[5] = 0;
      fVmin[6] = 0;
      fVmax[6] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadBDTF() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const override;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   double fVmin[7];
   double fVmax[7];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[7];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<BDTFNode*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadBDTF::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   double norm  = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      BDTFNode *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(BDTFNode*)current->GetRight();
         else current=(BDTFNode*)current->GetLeft();
      }
      myMVA += fBoostWeights[itree] *  current->GetNodeType();
      norm  += fBoostWeights[itree];
   }
   return myMVA /= norm;
}

void ReadBDTF::Initialize()
{
  double inf = std::numeric_limits<double>::infinity();
  double nan = std::numeric_limits<double>::quiet_NaN();
  // itree = 0
  fBoostWeights.push_back(1.99124073453835);
  fForest.push_back( 
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.964696,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 53.7522, 0.364373, -9004.08, 0.802185, -2.21001, 33.4336, -8.49216, -53.4932, 7, 0.579023, 0, 0, 0.5,-99)    );
  // itree = 1
  fBoostWeights.push_back(1.10666);
  fForest.push_back( 
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.819717,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 34.5577, 0.265597, -8037.07, 0.389414, -1.10685, 12.4735, -4.17044, -34.4601, 7, 0.305806, 0, 0, 0.448137,-99)    );
  // itree = 2
  fBoostWeights.push_back(0.892667);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.722287,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.999207, 0, 0, 0.611346,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.997621, 0, 0, 0.3736,-99)    );
  // itree = 3
  fBoostWeights.push_back(1.17863);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.781587,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00481871, 0, 0, 0.659843,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.500786,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.309506,-99)    );
  // itree = 4
  fBoostWeights.push_back(0.525356);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0.997621, 0, -1, 0.259088,-99)    );
  // itree = 5
  fBoostWeights.push_back(0.591807);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.613199,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 6, -0.000322764, 1, 0, 0.518295,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.997621, 0, 0, 0.371601,-99)    );
  // itree = 6
  fBoostWeights.push_back(0.639436);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.589333,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.904793, 0, 0, 0.517026,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.431087,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.312474,-99)    );
  // itree = 7
  fBoostWeights.push_back(0.694826);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.655487,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.278505,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00659567, 0, 0, 0.390916,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.339712,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.261491,-99)    );
  // itree = 8
  fBoostWeights.push_back(0.360453);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0.997621, 0, -1, 0.327194,-99)    );
  // itree = 9
  fBoostWeights.push_back(0.442554);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.584449,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 1000.35, -0.357397, 7489.74, -0.466654, 0.995776, -22.7751, -41.1604, -999.766, 7, -0.453988, 0, 0, 0.501592,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.997621, 0, 0, 0.41085,-99)    );
  // itree = 10
  fBoostWeights.push_back(0.629422);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.694869,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.290851,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00501615, 1, 0, 0.47512,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.427964,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.353384,-99)    );
  // itree = 11
  fBoostWeights.push_back(0.239714);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0.00343227, 0, -1, 0.382387,-99)    );
  // itree = 12
  fBoostWeights.push_back(0.315138);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.558967,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 12.8144, 0.294893, -1848.28, 1.64839, -3.9999, -18.0319, -1.02882, -13.0714, 7, -0.224263, 0, 0, 0.507481,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.440357,-99)    );
  // itree = 13
  fBoostWeights.push_back(0.223359);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0.997621, 0, -1, 0.390141,-99)    );
  // itree = 14
  fBoostWeights.push_back(0.252996);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.541594,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 6, -0.000322764, 1, 0, 0.498475,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.997621, 0, 0, 0.444391,-99)    );
  // itree = 15
  fBoostWeights.push_back(0.200705);
  fForest.push_back( 
NN(
0, 
0, 
8, 13.0411, 0.232438, -4982.61, 0.730239, -1.92872, 4.39183, -5.62604, -13.3373, -1, -0.0662198, 0, -1, 0.400974,-99)    );
  // itree = 16
  fBoostWeights.push_back(0.158029);
  fForest.push_back( 
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.516266,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 13.238, 0.235946, -5057.81, 0.741261, -1.95783, 4.45812, -5.71095, -13.5386, 7, -0.0672193, 0, 0, 0.449991,-99)    );
  // itree = 17
  fBoostWeights.push_back(0.451116);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.59255,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00481871, 0, 0, 0.505053,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.466818,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.419696,-99)    );
  // itree = 18
  fBoostWeights.push_back(0.286806);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0.997621, 0, -1, 0.360404,-99)    );
  // itree = 19
  fBoostWeights.push_back(0.150249);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.501961,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.999207, 0, 0, 0.466995,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.997621, 0, 0, 0.428786,-99)    );
  // itree = 20
  fBoostWeights.push_back(0.200401);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0.00343227, 0, -1, 0.40112,-99)    );
  // itree = 21
  fBoostWeights.push_back(0.168796);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.519431,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 11.1333, 0.429159, -1207.87, 2.33897, -5.57398, -30.89, 2.3604, -11.4964, 7, -0.222628, 0, 0, 0.485399,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.450067,-99)    );
  // itree = 22
  fBoostWeights.push_back(0.165376);
  fForest.push_back( 
NN(
0, 
0, 
8, 12.7964, 0.292395, -5360.99, 1.02345, -2.6235, -0.305105, -6.573, -13.1639, -1, -0.108229, 0, -1, 0.418058,-99)    );
  // itree = 23
  fBoostWeights.push_back(0.0826879);
  fForest.push_back( 
NN(
0, 
0, 
8, 12.9276, 0.295392, -5415.94, 1.03394, -2.65039, -0.308232, -6.64037, -13.2989, -1, -0.109338, 0, -1, 0.45875,-99)    );
  // itree = 24
  fBoostWeights.push_back(0.109837);
  fForest.push_back( 
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.518406,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 12.9607, 0.296149, -5429.82, 1.03659, -2.65719, -0.309022, -6.6574, -13.333, 7, -0.109619, 0, 0, 0.47934,-99)    );
  // itree = 25
  fBoostWeights.push_back(0.335325);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.573934,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00481871, 0, 0, 0.513484,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.486012,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.455777,-99)    );
  // itree = 26
  fBoostWeights.push_back(0.199324);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0.997621, 0, -1, 0.401637,-99)    );
  // itree = 27
  fBoostWeights.push_back(0.125395);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.507154,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.999207, 0, 0, 0.478745,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.997621, 0, 0, 0.450333,-99)    );
  // itree = 28
  fBoostWeights.push_back(0.601318);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.947844,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.361558,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.994834, 1, 0, 0.515895,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.990949, 0, 0, 0.451912,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.904762, 0, 0, 0.425459,-99)    );
  // itree = 29
  fBoostWeights.push_back(0.410002);
  fForest.push_back( 
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.62497,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 15.0238, 0.296572, -5430.08, 0.682924, -1.82646, -10.4339, -5.33641, -15.3003, 7, -0.00813548, 0, 0, 0.509541,-99)    );
  // itree = 30
  fBoostWeights.push_back(0.609443);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.787903,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.322082,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.99957, 0, 0, 0.528572,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.990949, 0, 0, 0.465416,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.904762, 0, 0, 0.441173,-99)    );
  // itree = 31
  fBoostWeights.push_back(0.385429);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.763337,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.405575,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00659567, 0, 0, 0.525106,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.501539,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.475703,-99)    );
  // itree = 32
  fBoostWeights.push_back(0.212919);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.565508,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 412.181, 3.62697, 8887, 0.982171, -2.57611, -17.4876, -21.5453, -415.789, 7, -0.463527, 0, 0, 0.541797,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 14.6233, 0.30802, -5587.37, 0.746584, -2.012, -6.14563, -5.53113, -14.9528, 7, -0.0850026, 0, 0, 0.514265,-99)    );
  // itree = 33
  fBoostWeights.push_back(0.281793);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.564512,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00481871, 0, 0, 0.516248,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.49421,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.470183,-99)    );
  // itree = 34
  fBoostWeights.push_back(0.160295);
  fForest.push_back( 
NN(
0, 
0, 
8, 14.9147, 0.316372, -5607.05, 0.911744, -2.39396, -10.8432, -5.51205, -15.2389, -1, -0.126028, 0, -1, 0.420532,-99)    );
  // itree = 35
  fBoostWeights.push_back(0.0801476);
  fForest.push_back( 
NN(
0, 
0, 
8, 15.0583, 0.319418, -5661.05, 0.920525, -2.41702, -10.9476, -5.56513, -15.3857, -1, -0.127242, 0, -1, 0.460012,-99)    );
  // itree = 36
  fBoostWeights.push_back(0.0936738);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.514291,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.99866, 0, 0, 0.500077,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 15.0946, 0.320188, -5674.68, 0.922742, -2.42284, -10.974, -5.57853, -15.4227, 7, -0.127549, 0, 0, 0.479974,-99)    );
  // itree = 37
  fBoostWeights.push_back(0.366783);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.659135,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.358595,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00501615, 1, 0, 0.49642,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.478875,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.459518,-99)    );
  // itree = 38
  fBoostWeights.push_back(0.239637);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.552099,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.990968, 0, 0, 0.50444,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.904763, 0, 0, 0.488659,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.471389,-99)    );
  // itree = 39
  fBoostWeights.push_back(0.163908);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.504955,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00481871, 0, 0, 0.455914,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.441287,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.427155,-99)    );
  // itree = 40
  fBoostWeights.push_back(0.631084);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.93039,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.302095,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.994834, 1, 0, 0.447441,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.990949, 0, 0, 0.410391,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.904762, 0, 0, 0.397507,-99)    );
  // itree = 41
  fBoostWeights.push_back(0.731164);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.758609,-99) , 
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.703062,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0.0376855, 1, 0, 0.430068,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0.168071, 0, 0, 0.501847,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
8, 17.1163, 0.292928, -5388.71, 0.709996, -1.99398, -13.8425, -5.79349, -17.3873, 7, -0.113062, 0, 0, 0.484881,-99)    );
  // itree = 42
  fBoostWeights.push_back(0.397258);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, 0.602624,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.273603,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00501615, 1, 0, 0.431323,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00759676, 1, 0, 0.414801,-99) , 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0,-99) , 
0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0.00343227, 0, 0, 0.403164,-99)    );
  // itree = 43
  fBoostWeights.push_back(0.189396);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.406418,-99)    );
  // itree = 44
  fBoostWeights.push_back(0.094698);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.452792,-99)    );
  // itree = 45
  fBoostWeights.push_back(0.047349);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.476343,-99)    );
  // itree = 46
  fBoostWeights.push_back(0.0236745);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.488165,-99)    );
  // itree = 47
  fBoostWeights.push_back(0.0118373);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.494082,-99)    );
  // itree = 48
  fBoostWeights.push_back(0.00591863);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.497041,-99)    );
  // itree = 49
  fBoostWeights.push_back(0.00295931);
  fForest.push_back( 
NN(
0, 
0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, -1, 0.49852,-99)    );
   return;
};

// Clean up
inline void ReadBDTF::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}

inline double ReadBDTF::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!IsStatusClean()) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                << " because status is dirty" << std::endl;
   }
   else {
         retval = GetMvaValue__( inputValues );
   }

   return retval;
}
